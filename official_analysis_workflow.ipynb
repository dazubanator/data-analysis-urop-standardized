{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Official UROP Data Analysis Workflow\n",
        "\n",
        "This notebook provides a complete, reproducible pipeline for analyzing schema experiment data as part of the UROP project.\n",
        "\n",
        "## Setup Instructions\n",
        "1. Click **Runtime** > **Run all** to process the default dataset.\n",
        "2. To analyze your own data, upload CSV files to the `data/raw` folder or mount Google Drive."
      ],
      "metadata": {
        "id": "intro"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Environment Setup\n",
        "\n",
        "Clone the repository and install the standard analysis package. \n",
        "\n",
        "> **⚠️ REQUIRED ACTION**: If you are seeing `KeyError: 'mean'`, you **MUST** go to **Runtime > Restart session** after running this cell for the package updates to take effect."
      ],
      "metadata": {
        "id": "setup_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean up any previous clone to ensure a fresh pull\n",
        "!rm -rf data-analysis-urop-standardized\n",
        "\n",
        "# Clone the repository\n",
        "!git clone https://github.com/dazubanator/data-analysis-urop-standardized.git\n",
        "\n",
        "# Install the package (forcing upgrade)\n",
        "!pip install -v -q --upgrade ./data-analysis-urop-standardized\n",
        "\n",
        "print(\"✓ Environment setup complete!\")\n",
        "print(\"\\n--- ACTION REQUIRED ---\")\n",
        "print(\"If this is your first run today or you just pulled an update:\")\n",
        "print(\"Go to top menu: Runtime > Restart session (or Restart runtime) NOW.\")"
      ],
      "metadata": {
        "id": "setup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Imports and Configuration\n",
        "\n",
        "Import required libraries and set the analysis parameters."
      ],
      "metadata": {
        "id": "import_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from schema_analysis.data_loader import load_and_merge_csvs\n",
        "from schema_analysis import TubeTrials\n",
        "\n",
        "# Set high-quality plotting style\n",
        "sns.set_theme(style=\"whitegrid\", palette=\"muted\")\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "plt.rcParams['figure.dpi'] = 100\n",
        "\n",
        "# Standard experimental parameters\n",
        "DATA_PATH = '/content/data-analysis-urop-standardized/data/raw'\n",
        "MIN_ANGLE = 3\n",
        "MAX_ANGLE = 43\n",
        "MAX_INVALID_TRIALS = 2\n",
        "\n",
        "print(\"✓ Configuration loaded.\")"
      ],
      "metadata": {
        "id": "imports"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Data Processing Pipeline\n",
        "\n",
        "Loading, cleaning, and filtering the experimental data."
      ],
      "metadata": {
        "id": "processing_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Starting Pipeline...\")\n",
        "\n",
        "# 1. Load & Merge Data\n",
        "merged_df = load_and_merge_csvs(DATA_PATH)\n",
        "print(f\"[LOAD] Loaded {len(merged_df)} raw trials.\")\n",
        "\n",
        "# 2. Clean Data (Remove missing group_id)\n",
        "merged_df = merged_df.dropna(subset=['session_group'])\n",
        "print(f\"[CLEAN] {len(merged_df)} trials remain after removing empty group IDs.\")\n",
        "\n",
        "# 3. Process Angles and Validity\n",
        "trials = TubeTrials(merged_df)\n",
        "trials.process_angles()\n",
        "trials.mark_valid_angles(min_angle=MIN_ANGLE, max_angle=MAX_ANGLE)\n",
        "trials.mark_valid_subjects(max_invalid_trials=MAX_INVALID_TRIALS)\n",
        "\n",
        "# 4. Selection and Balancing\n",
        "clean_trials = trials.select(valid_only=True)\n",
        "results = clean_trials.calc_d_values()\n",
        "stats_df = clean_trials.calc_stats()\n",
        "\n",
        "# 5. Attrition Report\n",
        "trials.get_validity_stats()\n",
        "\n",
        "print(f\"\\n[FINALIZE] {len(results)} valid pairs identified for analysis.\")"
      ],
      "metadata": {
        "id": "pipeline"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Results Summary\n",
        "\n",
        "Aggregated statistics per Face ID."
      ],
      "metadata": {
        "id": "results_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"STATISTICS BY FACE ID\")\n",
        "print(\"=\" * 30)\n",
        "if not stats_df.empty:\n",
        "    # Robust column mapping if using old version in memory\n",
        "    if 'mean' not in stats_df.columns and 'mean_D' in stats_df.columns:\n",
        "        print(\"\\n⚠️ NOTICE: Using old column names from memory. Please restart runtime for official fix.\")\n",
        "        mapper = {'mean_D': 'mean', 'std_D': 'std'}\n",
        "        stats_df = stats_df.rename(columns=mapper)\n",
        "        if 'sem' not in stats_df.columns:\n",
        "            # Estimate SEM if on old version\n",
        "            stats_df['sem'] = stats_df['std'] / np.sqrt(stats_df['n_subjects'])\n",
        "    \n",
        "    display(stats_df)\n",
        "    if 'd' in results.columns:\n",
        "        print(\"\\nGLOBAL D-VALUE MEAN: {:.4f}°\".format(results['d'].mean()))\n",
        "        print(\"GLOBAL D-VALUE SEM:  {:.4f}°\".format(results['d'].sem()))\n",
        "else:\n",
        "    print(\"No valid data to display statistics.\")"
      ],
      "metadata": {
        "id": "show_results"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Visualizations\n",
        "\n",
        "High-quality plots for publication and presentation."
      ],
      "metadata": {
        "id": "viz_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not stats_df.empty:\n",
        "    # Final check for required columns to avoid crash\n",
        "    if 'mean' in stats_df.columns:\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "        # Plot 1: D-value Distribution\n",
        "        sns.histplot(results['d'], bins=20, kde=True, ax=axes[0, 0], color='skyblue')\n",
        "        axes[0, 0].axvline(results['d'].mean(), color='red', linestyle='--', label=f\"Mean: {results['d'].mean():.2f}\")\n",
        "        axes[0, 0].set_title('Distribution of D-values (All Faces)')\n",
        "        axes[0, 0].set_ylabel('Frequency (D-values)')\n",
        "        axes[0, 0].legend()\n",
        "\n",
        "        # Plot 2: Boxplot by Face ID\n",
        "        order = sorted(results['face_id'].unique())\n",
        "        sns.boxplot(data=results, x='face_id', y='d', order=order, ax=axes[0, 1], palette='pastel')\n",
        "        axes[0, 1].set_title('D-value Spread per Face ID')\n",
        "\n",
        "        # Plot 3: Mean D-value with SEM\n",
        "        axes[1, 0].bar(stats_df['face_id'].astype(str), stats_df['mean'], yerr=stats_df['sem'].fillna(0), capsize=5, color='teal', alpha=0.7)\n",
        "        axes[1, 0].set_title('Mean D-value per Face (±SEM)')\n",
        "        axes[1, 0].set_ylabel('D-value (degrees)')\n",
        "\n",
        "        # Plot 4: P-values\n",
        "        colors = ['#2ecc71' if p < 0.05 else '#e74c3c' for p in stats_df['p_value']]\n",
        "        axes[1, 1].bar(stats_df['face_id'].astype(str), stats_df['p_value'], color=colors, alpha=0.8)\n",
        "        axes[1, 1].axhline(0.05, color='black', linestyle=':', label='p=0.05 Threshold')\n",
        "        axes[1, 1].set_title('Statistical Significance (P-value)')\n",
        "        axes[1, 1].set_yscale('log')\n",
        "        axes[1, 1].legend()\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(\"Error: 'mean' column still missing. YOU MUST RESTART THE RUNTIME (Runtime > Restart session).\")\n",
        "else:\n",
        "    print(\"No valid data to visualize.\")"
      ],
      "metadata": {
        "id": "viz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Official Verification\n",
        "\n",
        "Verify the pipeline logic using a standardized verification script and dummy data."
      ],
      "metadata": {
        "id": "verif_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/data-analysis-urop-standardized/verification/run_verification.py"
      ],
      "metadata": {
        "id": "verif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**Project Repository**: [dazubanator/data-analysis-urop-standardized](https://github.com/dazubanator/data-analysis-urop-standardized)"
      ],
      "metadata": {
        "id": "footer"
      }
    }
  ]
}